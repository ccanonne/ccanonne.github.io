\documentclass[11pt]{article}
%Gummi|065|=)
\title{Privacy Doona: Why We Should Hide Among The Clones\\[.5em]\small{}(Written for the \href{https://differentialprivacy.org}{\textcolor{black}{DifferentialPrivacy.org}} website)}
\author{Cl\'ement Canonne}
\date{May 2022}
\usepackage{microtype}
\usepackage{palatino}
\usepackage{fullpage}
\usepackage[dvipsnames]{xcolor}
\usepackage[colorlinks,citecolor=blue,pagebackref=true]{hyperref}
\usepackage{amsmath,amssymb}
\usepackage{filecontents}
\usepackage{emoji}
\begin{document}
\maketitle

In this blog post, we will discuss a recent(ish) result of Feldman, McMillan, and Talwar~\cite{FeldmanMT21}, which provides an improved and simple analysis of the so-called ``amplification by shuffling'' formally connecting local privacy (LDP) and shuffle privacy.\footnote{The title of this post is a reference to the title of~\cite{FeldmanMT21}, ``Hiding Among The Clones,'' and to the notion of \emph{privacy blanket} introduced by Balle, Bell, Gasc\'{o}n, and Nissim~\cite{BalleBGN19}. Intuitively, the ``amplification by shuffling'' paradigm can be seen as anonymizing the messages from local randomizers, whose message distribution can be mathematically decomposed as a mixture of ``noise distribution not depending on the user's input'' and ``distribution actually depending on their input.'' As a result, each user randomly sends a message from the first or second distribution of the mixture.  But the shuffling then hides the informative messages (drawn from the second part of the mixture) among the non-informative (noise) ones: so the noise messages end up providing a ``privacy blanket'' in which sensitive information is safely and soundly wrapped.} Now, I'll assume the reader is familiar with both LDP and Shuffle DP: if not, a quick-and-dirty refresher (with less quick, and less dirty references) can be found \href{https://differentialprivacy.org/trustmodels/}{here}, and of course there is also Albert Cheu's excellent survey on Shuffle DP~\cite{Cheu21}.

I will also ignore most of the historical details, but it is worth mentioning that~\cite{FeldmanMT21} is not the first paper on this ``amplification by shuffling,'' (which, for local reasons, I'll just call a \emph{privacy doona}) but rather is the culmination of a rather long line of work involving many cool ideas and papers, starting with~\cite{CheuSUZZ19,ErlingssonFMRTT19}: I'd refer the reader to Table~1 in~\cite{FeldmanMT21} for an overview.

Alright, now that the caveats are behind us, what \emph{is} ``amplification by shuffling''? In a nutshell, it is capturing the (false!) intuition that ``anonymization provides privacy'' (which, again, is false! Don't do this!) and making it... less false. The idea is that while \emph{anonymization does not provide in itself any meaningful privacy guarantee}, it can \emph{amplify existing, rigorous privacy guarantee}. So if I start with a somewhat lousy LDP guarantee, but then all the messages sent by all users are completely anonymized, then my lousy LDP guarantee suddenly gets \emph{much} stronger (roughly speaking, the $\varepsilon$ parameter goes down with the square root of of the number of users involved). Which is wonderful! Let's see what this means, quantitatively.

\paragraph{The result of Feldman, McMillan, and Talwar.}
Here, we will focus on the simpler case of \emph{noninteractive} protocols (one-shot messages from the users to the central server, no funny business with messages going back and forth); which is conceptually simpler to state and parse, still very rich and interesting, and, well, very relevant in practice (being the easiest and cheapest to deploy). If you want the results in their full glorious generality, though, they are in the paper.

What the main theorem of~\cite{FeldmanMT21} is saying for this noninteractive setting can then be stated as follows: if I have an \emph{$\varepsilon_{L}$-locally private} (LDP) protocol for a task, where all $n$ users pass their data through the same randomizer (algorithm) $R$ and send the resulting message $y_i \gets R(x_i)$, then just permuting the messages $y_1\dots,y_n$ immediately gives an $(\varepsilon,\delta)$-\emph{shuffle} private protocol for the same task, for any pair $(\varepsilon,\delta)$ which satisfies
\begin{equation}
	\label{eq:eps:epsL}
		\varepsilon \leq \log\!\left( 1+ 16\frac{e^{\varepsilon_{L}}-1}{e^{\varepsilon_{L}}+1}\sqrt{\frac{e^{\varepsilon_{L}}\log\frac{4}{\delta}}{n}}\right)
\end{equation}
as long as $n \gg e^{\varepsilon_{L}}\log(1/\delta)$. That is quite a lot to parse, though: what does this actually \emph{mean}?\medskip 

\textbf{First}, the assumption that all users have the same randomizer (or at least cannot be distinguished by their randomizer) is quite natural: if they didn't, then we wouldn't be able to say anything in general, since the randomizer they use could just give away their identity completely. For instance, as an extreme case, the randomizer of user $i$ could just append $i$ to the message (it's OK, still LDP!), and then shuffling achieves exactly nothing: we know who sent what. So OK, asking for all randomizers to be the same is not really a restriction.\medskip 

\textbf{Second}, each user only sends one message, and this preserves its length (we just shuffled the messages, didn't modify them!). So if you start with an LDP protocol with amazing features XYZ (e.g., the messages are $1$-bit long, or users don't share a random seed, or the randomizers run in time $O(1)$), then the shuffle protocol enjoys exactly the same properties. (It only enjoys naturally some \emph{robustness}, in the sense that if $10\%$ if the $n$ users maliciously deviate from the protocol, they can't really jeopardize the privacy of the remaining $90\%$ of users.\footnote{More specifically, they can completely jeopardize the \emph{utility} (accuracy) of the result, but in terms of privacy, all they can do is slightly reduce it: if $10\%$ of users are malicious, the remaining $90\%$ still get the privacy amplification of guarantee of~\eqref{eq:eps:epsL}, but with $0.9n$ instead of $n$.} Which is... good.)\medskip 

\textbf{Third}, this is inherently approximate DP. Here we started with pure LDP (you can also extend that to approximate LDP) and ended up with approximate Shuffle DP: this is not a mistake, that's how it is. I am not a purist (erm) myself, and that looks more than good enough to me; but if you seek pure Shuffle DP, then this result is not the droid you're looking for.\medskip 

Alright, \emph{what} is this guarantee stated in~\eqref{eq:eps:epsL} giving us? Let's interpret the expression in~\eqref{eq:eps:epsL} in two parameter regimes, focusing on $\varepsilon$ (fixing some small $\delta>0$). If we start with $\varepsilon_{L} \ll 1$ for our LDP randomizers $R$, then a first-order Taylor expansion shows that we get
\begin{equation}
		\varepsilon \approx \varepsilon_{L}\cdot 8\sqrt{\frac{\log\frac{4}{\delta}}{n}}
\end{equation}
so that \emph{shuffling improved our privacy parameter by a factor $\sqrt{n}$}.\footnote{Of course, we started with a local privacy guarantee, and ended up with a shuffle privacy guarantee: so the two are incomparable, and one has to interpret this ``amplification'' in that context.} \emoji{astonished}
This is great! With more users, comes more privacy!

But that was starting with small $\varepsilon_{L}$, that is, already pretty good privacy guarantees for our LDP ``building block'' $R$. What happens if we start with ``somewhat lousy'' privacy guarantees, that is, $\varepsilon_{L} \gg 1$? Do we get anything interesting then?
Another Taylor expansion (everything is a Taylor expansion) shows us that, then,
\begin{equation}
	\label{eq:epsL:ll:one}
		\varepsilon \approx \log\!\left( 1+ 8\sqrt{\frac{e^{\varepsilon_{L}}\log\frac{4}{\delta}}{n}}\right)
\end{equation}
or, put differently,
\begin{equation}
	\label{eq:epsL:gg:one}
		\varepsilon \approx 8e^{\varepsilon_{L}/2}\sqrt{\frac{\log\frac{4}{\delta}}{n}}
\end{equation}
That's a bit harder to interpret, but that seems\dots{} useful? It is: let us see how much, with a couple examples.

\begin{description}
\item[Learning.]
The first one is distribution learning, a.k.a. density estimation: you have $n$ i.i.d.\ samples (one per user) from an unknown probability distribution $\mathbf{p}$ over a discrete domain of size $k$, and your goal is to output an estimate $\widehat{\mathbf{p}}$ such that, with high (say, constant) probability, $\mathbf{p}$ and $\widehat{\mathbf{p}}$ are close in \emph{total variation distance}:
\[
		\operatorname{TV}(\mathbf{p},\widehat{\mathbf{p}}) = \sup_{S\subseteq [k]} (\mathbf{p}(S) - \widehat{\mathbf{p}}(S) ) \leq \alpha
\]
(if total variation distance seems a bit mysterious, it's exactly half the $\ell_1$ distance between the probability mass functions). We know how to solve this problem in the non-private setting: $n=\Theta\!\left( \frac{k}{\alpha^2} \right)$ samples are necessary and sufficient. We know how to solve this problem in the (central) DP setting: $n=\Theta\!\left( \frac{k}{\alpha^2} + \frac{k}{\alpha\varepsilon} \right)$ samples are necessary and sufficient~\cite{DiakonikolasHS15}. We know how to solve this problem in the LDP setting: 
\begin{equation}
	\label{eq:learning:ldp}
n=\Theta\!\left(\frac{k^2}{\alpha^2(e^\varepsilon-1)^2}+\frac{k^2}{\alpha^2e^\varepsilon}+\frac{k}{\alpha^2}\right)
\end{equation}
samples are necessary and sufficient~\cite{AcharyaSZ19} (note that the first term is just $k/(\alpha^2\varepsilon^2)$ for small $\varepsilon$). Now, as they say in Mulan: \emph{let's make a shuffle DP algo out of you.}

If we want to achieve $(\varepsilon,\delta)$-shuffle DP, we need to select $\varepsilon_L$. Based on~\eqref{eq:epsL:ll:one} and~\eqref{eq:epsL:gg:one}, and ignoring pesky constants we will choose it so that
\begin{equation}
	\label{eq:choice:epsL}
	 \varepsilon_{L} \approx \varepsilon \sqrt{\frac{n}{\log(1/\delta)}}  \quad\text{ or }\quad e^{\varepsilon_{L}} \approx \varepsilon^2 \cdot \frac{n}{\log(1/\delta)}\,.
\end{equation}
depending on whether $\frac{\varepsilon^2 n}{\log(1/\delta)}\geq 1$. Plugging that back in~\eqref{eq:learning:ldp}, we see that the first case corresponds to the first term (small $\varepsilon_{L}$) and the second to the second term ($\varepsilon_{L} \geq 1$), and overall the condition on $n$ for the original LDP algorithm to 
successful learn the distribution becomes
\[
	n \gtrsim 
	\frac{k^2}{\alpha^2(e^{\varepsilon_{L}}-1)^2}+\frac{k^2}{\alpha^2e^{\varepsilon_{L}}}+\frac{k}{\alpha^2}
	\approx \frac{k^2\log(1/\delta)}{\alpha^2\varepsilon^2 n}+\frac{k^2\log(1/\delta)}{\alpha^2\varepsilon^2 n}+\frac{k}{\alpha^2}
	 \approx \frac{k^2\log(1/\delta)}{\alpha^2\varepsilon^2 n}+\frac{k}{\alpha^2}
\]
(where $\gtrsim$ means ``let's ignore constants''). There is an $n$ in the RHS as well, so reorganizing and handling the two terms separately the condition on $n$ becomes
\[
	n \gtrsim \frac{k \sqrt{\log(1/\delta)}}{\alpha\varepsilon}+\frac{k}{\alpha^2}
\]
which... is great? We immediately get a sample complexity $O\!\left(\frac{k}{\alpha^2}+\frac{k \sqrt{\log(1/\delta)}}{\alpha\varepsilon}\right)$ in the shuffle DP model, which (ignoring the $\sqrt{\log(1/\delta)}$) matches the one in the \emph{central} DP setting! 

\paragraph{tl;dr:} Taking an optimal LDP algorithm and just shuffling the messages \emph{immediately} gives an optimal shuffle DP algorithm, no extra work needed.
\item[(Uniformity) Testing.] Alright, maybe it was a fluke? Let's look at another ``basic'' problem close to my heart: we don't want to learn the probability distribution $\mathbf{p}$, just test whether it is actually \emph{the} uniform distribution\footnote{You can here replace uniform by any known distribution $\mathbf{q}$ of your choosing, that doesn't change the question (and result), but uniform is nice.} $\mathbf{u}$ on the domain $[k]=\{1,2,\dots,k\}$. So if $\mathbf{p} =\mathbf{u}$, you've got to say ``yes'' with probability at least $2/3$, and if $\operatorname{TV}(\mathbf{p},\mathbf{u})>\alpha$, then you need to say ``no'' with probability at least $2/3$.

This is also well understood in the non-private setting ($n=\Theta(\sqrt{k}/\alpha^2)$)~\cite{Paninski08} [see also \href{https://ccanonne.github.io/survey-topics-dt.html}{my upcoming survey}], in the central DP setting ($n=\Theta\!\left( \frac{\sqrt{k}}{\alpha^2} + \frac{\sqrt{k}}{\alpha\sqrt{\varepsilon}}+\frac{k^{1/3}}{\alpha^{4/3}\varepsilon^{2/3}} + \frac{1}{\alpha\varepsilon} \right)$)~\cite{AcharyaSZ18,AliakbarpourDR18}, and in the LDP setting, where the result differs on whether the users can communicate or share a common random seed 
\begin{equation}
	\label{eq:testing:ldp:publiccoin}
	n=\Theta\!\left( \frac{k}{\alpha^2(e^\varepsilon-1)^2} + \frac{k}{\alpha^2e^{\varepsilon/2}} + \frac{\sqrt{k}}{\alpha^2}\right)
\end{equation} or not 
\begin{equation}
	\label{eq:testing:ldp:privatecoin}
	n=\Theta\!\left( \frac{k^{3/2}}{\alpha^2(e^\varepsilon-1)^2} + \frac{k^{3/2}}{\alpha^2e^{\varepsilon}} + \frac{\sqrt{k}}{\alpha^2}\right)
\end{equation}
as established in a sequence of papers~\cite{AcharyaCT21,AminJM20,AcharyaCFST21,AcharyaCLST22,CanonneL22}. %More in \href[https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/private-goodness-of-fit.pdf]{this note of mine} for a summary.

Now, say you want an ($\varepsilon,\delta)$-shuffle DP algorithm for uniformity testing, but don't want to design one from scratch (though it \emph{is} possible to do so, and some did~\cite{BalcerCJM21,CanonneL22,CheuY21}). Let's say you want to look at the ``no-common-random-seed-shared-by-users'' model (a.k.a.\ \emph{private-coin} setting): so you stare at the corresponding LDP communication complexity,~\eqref{eq:testing:ldp:privatecoin}, and try to choose $\varepsilon_L$ to start with before shuffling. This will be the same as in the learning example (i.e., \eqref{eq:choice:epsL}): based on~\eqref{eq:epsL:ll:one} and~\eqref{eq:epsL:gg:one}, we will set
\begin{equation}
	 \varepsilon_{L} \approx \varepsilon \sqrt{\frac{n}{\log(1/\delta)}}  \quad\text{ or }\quad e^{\varepsilon_{L}} \approx \varepsilon^2 \cdot \frac{n}{\log(1/\delta)}\,.
\end{equation}
depending on whether $\frac{\varepsilon^2 n}{\log(1/\delta)}\geq 1$. Plugging this back in~\eqref{eq:testing:ldp:privatecoin} and quickly checking which case corresponds to each term, we then easily get that for our algorithm to correctly solve the uniformity testing problem, it suffices that the sample complexity (number of users) $n$ satisfies
\[
	n \gtrsim \frac{k^{3/2}}{\alpha^2(e^{\varepsilon_L}-1)^2} + \frac{k^{3/2}}{\alpha^2e^{\varepsilon_L}} + \frac{\sqrt{k}}{\alpha^2}
	 \approx \frac{k^{3/2}\log(1/\delta)}{\alpha^2\varepsilon^2 n } + \frac{\sqrt{k}}{\alpha^2}
\]
which, reorganizing and solving for $n$, means that it suffices to have 
\[
	n \gtrsim \frac{k^{3/4}\sqrt{\log(1/\delta)}}{\alpha\varepsilon} + \frac{\sqrt{k}}{\alpha^2}\,.
\]
And, \emph{voil\'a}! Even better, we also have strong evidence to suspect that this sample complexity $O\Big(\frac{k^{3/4}\sqrt{\log(1/\delta)}}{\alpha\varepsilon}+ \frac{\sqrt{k}}{\alpha^2}\Big)$ is tight among all private-coin algorithms.\footnote{As long as one is happy with approximate DP. One can achieve that in pure DP as well, but it's a bit more complicated~\cite{CheuY21}.}

Now, if you wanted to look at \emph{public-coin} shuffle DP protocols (with a common random seed available), then you would start with an optimal public-coin LDP algorithm (and look at~\eqref{eq:testing:ldp:publiccoin}), and setting $\varepsilon_L$ the same way you'd get a shuffle DP algorithm with sample complexity
\[
n=O\Big(\frac{k^{2/3}\log^{1/3}(1/\delta)}{\alpha^{4/3}\varepsilon^{2/3}} + \frac{\sqrt{k\log(1/\delta)}}{\alpha\varepsilon}+ \frac{\sqrt{k}}{\alpha^2}\Big)
\]
which, well, is \emph{also} strongly believed to be optimal!

\paragraph{tl;dr:} Here again, taking an optimal off-the-shelf LDP algorithm and just shuffling the messages \emph{immediately} gives an optimal shuffle DP algorithm, no extra work needed.
\end{description}

\paragraph{Conclusion.} I hope the above convinced you of how useful this privacy amplification can be: from an optimal LDP algorithm, featuring any extra appealing characteristics you like, \emph{just adding an extra shuffling step as postprocessing} yields an (often optimal? At least good) shuffle DP algorithm, \emph{with the same characteristics} and built-in robustness against malicious users.

All you need is to make sure that your starting point, the LDP algorithm satisfies a couple things: (1) all users have the same randomizer,\footnote{This is not such a big assumption usually, and there are somewhat-general ways to get to that using a logarithmic factor in the number of users.} and (2)~it works in all regimes of $\varepsilon$ (both high-privacy, $\varepsilon \leq 1$, \emph{and} low-privacy, $\varepsilon \gg 1$). Once you've got this, Bob's your uncle! You get shuffle DP algorithms for free.

It is not only appealing from a theoretical point of view, by the way! The authors of the paper worked hard to make their empirical analysis compelling as well, and their code is available \href{https://github.com/apple/ml-shuffling-amplification}{on GitHub}. But more importantly, from a practitioner's point of view, this means it is enough to design, implement, and test \emph{one} algorithm (the LDP one we start with) to automatically get a trusted one in the shuffle DP model as well: this reduces the risks of bugs, security failures, the amount of work spending tuning, testing...

\noindent So yes, whenever possible, we \emph{should} hide among the clones!

\begin{filecontents*}{blogpost.bib}

@inproceedings{FeldmanMT21,
  author    = {Vitaly Feldman and
               Audra McMillan and
               Kunal Talwar},
  title     = {Hiding Among the Clones: {A} Simple and Nearly Optimal Analysis of
               Privacy Amplification by Shuffling},
  booktitle = {{FOCS}},
  pages     = {954--964},
  publisher = {{IEEE}},
  year      = {2021}
}

@inproceedings{AcharyaSZ18,
  author    = {Jayadev Acharya and
               Ziteng Sun and
               Huanyu Zhang},
  title     = {Differentially Private Testing of Identity and Closeness of Discrete
               Distributions},
  booktitle = {NeurIPS},
  pages     = {6879--6891},
  year      = {2018}
}

@inproceedings{AcharyaSZ19,
  author    = {Jayadev Acharya and
               Ziteng Sun and
               Huanyu Zhang},
  title     = {Hadamard Response: Estimating Distributions Privately, Efficiently,
               and with Little Communication},
  booktitle = {{AISTATS}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  pages     = {1120--1129},
  publisher = {{PMLR}},
  year      = {2019}
}

@inproceedings{AliakbarpourDR18,
  author    = {Maryam Aliakbarpour and
               Ilias Diakonikolas and
               Ronitt Rubinfeld},
  title     = {Differentially Private Identity and Equivalence Testing of Discrete
               Distributions},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {169--178},
  publisher = {{PMLR}},
  year      = {2018}
}

@inproceedings{AminJM20,
  author    = {Kareem Amin and
               Matthew Joseph and
               Jieming Mao},
  title     = {Pan-Private Uniformity Testing},
  booktitle = {{COLT}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {125},
  pages     = {183--218},
  publisher = {{PMLR}},
  year      = {2020}
}

@inproceedings{BalcerCJM21,
  author    = {Victor Balcer and
               Albert Cheu and
               Matthew Joseph and
               Jieming Mao},
  title     = {Connecting Robust Shuffle Privacy and Pan-Privacy},
  booktitle = {{SODA}},
  pages     = {2384--2403},
  publisher = {{SIAM}},
  year      = {2021}
}

@inproceedings{BalleBGN19,
  author    = {Borja Balle and
               James Bell and
               Adri{\`{a}} Gasc{\'{o}}n and
               Kobbi Nissim},
  title     = {The Privacy Blanket of the Shuffle Model},
  booktitle = {{CRYPTO} {(2)}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11693},
  pages     = {638--667},
  publisher = {Springer},
  year      = {2019}
}

@inproceedings{CanonneL22,
  author    = {Cl{\'{e}}ment L. Canonne and
               Hongyi Lyu},
  title     = {Uniformity Testing in the Shuffle Model: Simpler, Better, Faster},
  booktitle = {{SOSA}},
  pages     = {182--202},
  publisher = {{SIAM}},
  year      = {2022}
}

@article{Cheu21,
  author    = {Albert Cheu},
  title     = {Differential Privacy in the Shuffle Model: {A} Survey of Separations},
  journal   = {CoRR},
  volume    = {abs/2107.11839},
  year      = {2021}
}

@inproceedings{CheuSUZZ19,
  author    = {Albert Cheu and
               Adam D. Smith and
               Jonathan R. Ullman and
               David Zeber and
               Maxim Zhilyaev},
  title     = {Distributed Differential Privacy via Shuffling},
  booktitle = {{EUROCRYPT} {(1)}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11476},
  pages     = {375--403},
  publisher = {Springer},
  year      = {2019}
}

@article{CheuY21,
  author    = {Albert Cheu and
               Chao Yan},
  title     = {Pure Differential Privacy from Secure Intermediaries},
  journal   = {CoRR},
  volume    = {abs/2112.10032},
  year      = {2021}
}

@inproceedings{DiakonikolasHS15,
  author    = {Ilias Diakonikolas and
               Moritz Hardt and
               Ludwig Schmidt},
  title     = {Differentially Private Learning of Structured Discrete Distributions},
  booktitle = {{NIPS}},
  pages     = {2566--2574},
  year      = {2015}
}

@inproceedings{ErlingssonFMRTT19,
  author    = {{\'{U}}lfar Erlingsson and
               Vitaly Feldman and
               Ilya Mironov and
               Ananth Raghunathan and
               Kunal Talwar and
               Abhradeep Thakurta},
  title     = {Amplification by Shuffling: From Local to Central Differential Privacy
               via Anonymity},
  booktitle = {{SODA}},
  pages     = {2468--2479},
  publisher = {{SIAM}},
  year      = {2019}
}

@article{Paninski08,
    AUTHOR = {Paninski, Liam},
     TITLE = {A coincidence-based test for uniformity given very sparsely
              sampled discrete data},
   JOURNAL = {IEEE Trans. Inform. Theory},
  FJOURNAL = {Institute of Electrical and Electronics Engineers.
              Transactions on Information Theory},
    VOLUME = {54},
      YEAR = {2008},
    NUMBER = {10},
     PAGES = {4750--4755},
      ISSN = {0018-9448},
   MRCLASS = {62F03 (94A12)},
  MRNUMBER = {2591136},
       DOI = {10.1109/TIT.2008.928987},
       URL = {https://doi.org/10.1109/TIT.2008.928987},
}

@article{AcharyaCT21,
    AUTHOR = {Acharya, Jayadev and Canonne, Cl\'{e}ment L. and Tyagi, Himanshu},
     TITLE = {Inference under information constraints {I}: {L}ower bounds
              from chi-square contraction},
   JOURNAL = {IEEE Trans. Inform. Theory},
  FJOURNAL = {Institute of Electrical and Electronics Engineers.
              Transactions on Information Theory},
    VOLUME = {66},
      YEAR = {2020},
    NUMBER = {12},
     PAGES = {7835--7855},
      ISSN = {0018-9448},
   MRCLASS = {62F30 (60B10 62B10 62F10 62R07)},
  MRNUMBER = {4191030},
       DOI = {10.1109/TIT.2020.3028440},
       URL = {https://doi.org/10.1109/TIT.2020.3028440},
}

@article{AcharyaCFST21,
  author    = {Jayadev Acharya and
               Cl{\'{e}}ment L. Canonne and
               Cody Freitag and
               Ziteng Sun and
               Himanshu Tyagi},
  title     = {Inference Under Information Constraints {III:} Local Privacy Constraints},
  journal   = {{IEEE} J. Sel. Areas Inf. Theory},
  volume    = {2},
  number    = {1},
  pages     = {253--267},
  year      = {2021}
}

@article{AcharyaCLST22,
  author    = {Jayadev Acharya and
               Cl{\'{e}}ment L. Canonne and
               Yuhan Liu and
               Ziteng Sun and
               Himanshu Tyagi},
  title     = {Interactive Inference Under Information Constraints},
  journal   = {{IEEE} Trans. Inf. Theory},
  volume    = {68},
  number    = {1},
  pages     = {502--516},
  year      = {2022}
}

\end{filecontents*}
\bibliographystyle{alpha}
\bibliography{blogpost}
\end{document}
